{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c1af0c-0125-4bea-abab-5654483a5666",
   "metadata": {},
   "source": [
    "# Build Anxiety Models \n",
    "This notebook contains all the code necessary to build, cross validate, and evaluate our models for Anxiety. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa166c-6641-41c2-a4d1-103bb39aa47f",
   "metadata": {},
   "source": [
    "# Load in Data and Explore Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fae1bf-8475-4249-8be9-0288d4d914ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "DATA_FILEPATH = 'data/anxiety.csv'\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Build Anxiety Models\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "train = spark.read.csv(DATA_FILEPATH,  inferSchema=True, header = True)\n",
    "DATA_FILEPATH = 'data/test.csv'\n",
    "test = spark.read.csv(DATA_FILEPATH,  inferSchema=True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2715ac7a-1f37-4191-ac44-03c141a73bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SES: double (nullable = true)\n",
      " |-- RuralVsUrban: double (nullable = true)\n",
      " |-- EducationDegree: double (nullable = true)\n",
      " |-- SecondaryVsPrimary: double (nullable = true)\n",
      " |-- TeachPublicVsOther: double (nullable = true)\n",
      " |-- YearsAsTeacher: double (nullable = true)\n",
      " |-- EmployedVsNot: double (nullable = true)\n",
      " |-- PastCOVIDpositive: double (nullable = true)\n",
      " |-- COVIDvaccinated: double (nullable = true)\n",
      " |-- PrePandemicChronIllness: double (nullable = true)\n",
      " |-- PrePandemicMentIllness: double (nullable = true)\n",
      " |-- PrePandemicNeuroDis: double (nullable = true)\n",
      " |-- Depression: integer (nullable = true)\n",
      " |-- Anxiety: integer (nullable = true)\n",
      " |-- OverallHealth: double (nullable = true)\n",
      " |-- COVIDfear: double (nullable = true)\n",
      " |-- RelatImprov: double (nullable = true)\n",
      " |-- WorkloadNowVsPreCOVID: double (nullable = true)\n",
      " |-- ResourceSatisfaction: double (nullable = true)\n",
      " |-- SufficientCOVIDmeasures: double (nullable = true)\n",
      " |-- MonthsOnlineTeach: double (nullable = true)\n",
      " |-- EducProblems: double (nullable = true)\n",
      " |-- BehavProblems: double (nullable = true)\n",
      " |-- EmotProblems: double (nullable = true)\n",
      " |-- SocialProblems: double (nullable = true)\n",
      " |-- FamilyProblems: double (nullable = true)\n",
      " |-- DiffOnlineTeach: double (nullable = true)\n",
      " |-- InstructAdjust: double (nullable = true)\n",
      " |-- BenefitOnlineTeach: double (nullable = true)\n",
      " |-- TotOnlineTraining: double (nullable = true)\n",
      " |-- BurnoutEmotExhaust: double (nullable = true)\n",
      " |-- BurnoutDepersonal: double (nullable = true)\n",
      " |-- BurnoutPerFulfill: double (nullable = true)\n",
      " |-- Man: integer (nullable = true)\n",
      " |-- Partnered: integer (nullable = true)\n",
      " |-- Bachelor's Degree: integer (nullable = true)\n",
      " |-- Diploma: integer (nullable = true)\n",
      " |-- Master's Degree: integer (nullable = true)\n",
      " |-- Non_university_studies: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Postdoctoral Fellowship: integer (nullable = true)\n",
      " |-- 0-5 years: integer (nullable = true)\n",
      " |-- 6-11 years: integer (nullable = true)\n",
      " |-- 12-16 years: integer (nullable = true)\n",
      " |-- 17-18 years: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00366d9-340c-4442-81b7-38b66ec3284d",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a30a2d-7105-4604-a761-8eaa99a7956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = train.columns\n",
    "column_list.remove('Anxiety')\n",
    "column_list.remove('_c0')\n",
    "train = train.withColumnRenamed('Anxiety', 'label')\n",
    "test = test.withColumnRenamed('Anxiety', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607b35b-8b55-49b7-b191-189093d6d18b",
   "metadata": {},
   "source": [
    "# Benchmark Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d131513-d3b8-4bd7-941e-507057ffb1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8819e96-0845-4f30-a1ff-20fe9d816286",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "lr = LogisticRegression(labelCol='label',\n",
    "                        featuresCol='scaledFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [0, .2, .4, .5, .6, .8, 1]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, .001]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "cvModel = crossval.setParallelism(4).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f172b0-745b-401c-a9a0-4304745486b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_b6d39b492788__elasticNetParam: 0.5\n",
      "LogisticRegression_b6d39b492788__regParam: 0.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0dc5c716-a554-4d41-b9a5-adc152b1b1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param set 1 Avg Metrics: 0.8222156491623472\n",
      "  elasticNetParam: 0.0\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 2 Avg Metrics: 0.8254080150063109\n",
      "  elasticNetParam: 0.0\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 3 Avg Metrics: 0.8253492607789543\n",
      "  elasticNetParam: 0.0\n",
      "  regParam: 0.001\n",
      "\n",
      "Param set 4 Avg Metrics: 0.8234676045610584\n",
      "  elasticNetParam: 0.2\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 5 Avg Metrics: 0.826026779822251\n",
      "  elasticNetParam: 0.2\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 6 Avg Metrics: 0.8254531628183647\n",
      "  elasticNetParam: 0.2\n",
      "  regParam: 0.001\n",
      "\n",
      "Param set 7 Avg Metrics: 0.818087291695732\n",
      "  elasticNetParam: 0.4\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 8 Avg Metrics: 0.8268036227870663\n",
      "  elasticNetParam: 0.4\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 9 Avg Metrics: 0.8254887287576786\n",
      "  elasticNetParam: 0.4\n",
      "  regParam: 0.001\n",
      "\n",
      "Param set 10 Avg Metrics: 0.8157424099885194\n",
      "  elasticNetParam: 0.5\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 11 Avg Metrics: 0.8269153599847812\n",
      "  elasticNetParam: 0.5\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 12 Avg Metrics: 0.8254338821913817\n",
      "  elasticNetParam: 0.5\n",
      "  regParam: 0.001\n",
      "\n",
      "Param set 13 Avg Metrics: 0.8130530383804353\n",
      "  elasticNetParam: 0.6\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 14 Avg Metrics: 0.8266890978212728\n",
      "  elasticNetParam: 0.6\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 15 Avg Metrics: 0.8255096104627213\n",
      "  elasticNetParam: 0.6\n",
      "  regParam: 0.001\n",
      "\n",
      "Param set 16 Avg Metrics: 0.809865792596265\n",
      "  elasticNetParam: 0.8\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 17 Avg Metrics: 0.8265658431671291\n",
      "  elasticNetParam: 0.8\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 18 Avg Metrics: 0.825656596392782\n",
      "  elasticNetParam: 0.8\n",
      "  regParam: 0.001\n",
      "\n",
      "Param set 19 Avg Metrics: 0.8026691805540531\n",
      "  elasticNetParam: 1.0\n",
      "  regParam: 0.1\n",
      "\n",
      "Param set 20 Avg Metrics: 0.8262626003479683\n",
      "  elasticNetParam: 1.0\n",
      "  regParam: 0.01\n",
      "\n",
      "Param set 21 Avg Metrics: 0.8256602482242958\n",
      "  elasticNetParam: 1.0\n",
      "  regParam: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = cvModel.avgMetrics\n",
    "all_params = cvModel.getEstimatorParamMaps()\n",
    "params= []\n",
    "for i in range(0, len(all_params)):\n",
    "    param = all_params[i]\n",
    "    for k, v in param.items():\n",
    "        params.append({f\"{k}\": f\"{v}\"})     \n",
    "for i in range(0, len(metrics)):\n",
    "    s = f'Param set {i+1} Avg Metrics: {metrics[i]}\\n'\n",
    "    params = all_params[i]\n",
    "    for k, v in params.items():\n",
    "        s+= f\"  {k.name}: {v}\\n\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1887be5c-eb4c-4b5b-aff7-d253dadfbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f17e13-aa9a-4f02-80e9-561cb4794d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7579617834394905\n",
      "Precision: 0.796875\n",
      "Recall: 0.8052631578947368\n",
      "F1 Score: 0.7576114961469753\n",
      "AUROC: 0.7453735144312394\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ada38-e17c-4ae7-8742-3ddd559d1597",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8d3595f-65f4-449a-b38d-088fbed88b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90c95ea0-3cd8-4170-a7a3-5d51aebd66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='label',\n",
    "                        featuresCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, rf])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [1, 5, 10, 15]) \\\n",
    "    .addGrid(rf.numTrees, [10, 15, 20, 25, 30, 35, 40, 45]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "rfModel = crossval.setParallelism(4).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17a314dd-aa9f-441c-8f39-d48d5752db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier_5a7fb866f669__maxDepth: 15\n",
      "RandomForestClassifier_5a7fb866f669__numTrees: 40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = rfModel.getEstimatorParamMaps()[np.argmax(rfModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7434544d-25fb-409e-9023-8a57d4db8c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param set 1 Avg Metrics: 0.7117251668859514\n",
      "  maxDepth: 1\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 2 Avg Metrics: 0.7560858442513432\n",
      "  maxDepth: 1\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 3 Avg Metrics: 0.7644090592038224\n",
      "  maxDepth: 1\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 4 Avg Metrics: 0.7685659842012551\n",
      "  maxDepth: 1\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 5 Avg Metrics: 0.7704840442426043\n",
      "  maxDepth: 1\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 6 Avg Metrics: 0.7871112342330036\n",
      "  maxDepth: 1\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 7 Avg Metrics: 0.7942737537249087\n",
      "  maxDepth: 1\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 8 Avg Metrics: 0.789018517911004\n",
      "  maxDepth: 1\n",
      "  numTrees: 45\n",
      "\n",
      "Param set 9 Avg Metrics: 0.823204684303359\n",
      "  maxDepth: 5\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 10 Avg Metrics: 0.8348237007000621\n",
      "  maxDepth: 5\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 11 Avg Metrics: 0.8285029207000176\n",
      "  maxDepth: 5\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 12 Avg Metrics: 0.8341806247384049\n",
      "  maxDepth: 5\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 13 Avg Metrics: 0.8343717999869938\n",
      "  maxDepth: 5\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 14 Avg Metrics: 0.8370885505735521\n",
      "  maxDepth: 5\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 15 Avg Metrics: 0.8374571349976473\n",
      "  maxDepth: 5\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 16 Avg Metrics: 0.8384989666418118\n",
      "  maxDepth: 5\n",
      "  numTrees: 45\n",
      "\n",
      "Param set 17 Avg Metrics: 0.8938308662334403\n",
      "  maxDepth: 10\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 18 Avg Metrics: 0.9092099675627873\n",
      "  maxDepth: 10\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 19 Avg Metrics: 0.9079621817836133\n",
      "  maxDepth: 10\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 20 Avg Metrics: 0.9174572086766304\n",
      "  maxDepth: 10\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 21 Avg Metrics: 0.9172280344100808\n",
      "  maxDepth: 10\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 22 Avg Metrics: 0.9215252313246546\n",
      "  maxDepth: 10\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 23 Avg Metrics: 0.9233724224215977\n",
      "  maxDepth: 10\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 24 Avg Metrics: 0.9270698535076672\n",
      "  maxDepth: 10\n",
      "  numTrees: 45\n",
      "\n",
      "Param set 25 Avg Metrics: 0.9210911900359285\n",
      "  maxDepth: 15\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 26 Avg Metrics: 0.933011546500832\n",
      "  maxDepth: 15\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 27 Avg Metrics: 0.9327040472421779\n",
      "  maxDepth: 15\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 28 Avg Metrics: 0.9390625474692629\n",
      "  maxDepth: 15\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 29 Avg Metrics: 0.9394922012455651\n",
      "  maxDepth: 15\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 30 Avg Metrics: 0.9417068276571665\n",
      "  maxDepth: 15\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 31 Avg Metrics: 0.9465398348648947\n",
      "  maxDepth: 15\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 32 Avg Metrics: 0.9458883311416555\n",
      "  maxDepth: 15\n",
      "  numTrees: 45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = rfModel.avgMetrics\n",
    "all_params = rfModel.getEstimatorParamMaps()\n",
    "params= []\n",
    "for i in range(0, len(all_params)):\n",
    "    param = all_params[i]\n",
    "    for k, v in param.items():\n",
    "        params.append({f\"{k}\": f\"{v}\"})     \n",
    "for i in range(0, len(metrics)):\n",
    "    s = f'Param set {i+1} Avg Metrics: {metrics[i]}\\n'\n",
    "    params = all_params[i]\n",
    "    for k, v in params.items():\n",
    "        s+= f\"  {k.name}: {v}\\n\"\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c392b3f4-e618-471b-b882-a7c77db3fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prediction = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f2414d8-43a7-4d55-bade-da3c98c169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7292993630573248\n",
      "Precision: 0.7312775330396476\n",
      "Recall: 0.8736842105263158\n",
      "F1 Score: 0.7175744477017777\n",
      "AUROC: 0.690874363327674\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(rf_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a5ba5-5721-49ed-9fb7-76c65a642d09",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2eaecdc-e596-46e4-97b7-4d21ca9b0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7833a575-d2d6-4f14-9714-af0119415c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [[len(column_list), k, k, 2] for k in [50, 75, 100]]\n",
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(labelCol='label', featuresCol='scaledFeatures', maxIter=1000, \n",
    "                                     blockSize=128, seed=1234, solver = 'gd')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, mlp])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(mlp.layers, layers)\\\n",
    "    .addGrid(mlp.stepSize, [.001, .005, .01, .05])\\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "# train the model\n",
    "mlpModel = crossval.setParallelism(6).fit(train) # train 6 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3528dd53-0d36-4e0c-a61f-9e94f2e418fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptronClassifier_d9c0df9f3942__layers: [45, 100, 100, 2]\n",
      "MultilayerPerceptronClassifier_d9c0df9f3942__stepSize: 0.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = mlpModel.getEstimatorParamMaps()[np.argmax(mlpModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674f710b-7d76-4576-ad46-36359697209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_prediction = mlpModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2574e262-2973-4dda-9e7e-35730c30e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7452229299363057\n",
      "Precision: 0.8089887640449438\n",
      "Recall: 0.7578947368421053\n",
      "F1 Score: 0.7469484268154996\n",
      "AUROC: 0.7418505942275042\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(mlp_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bcb33-9f26-4afa-9c65-1f79870bd1bb",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3e0ff0-6c5a-4cec-86d4-4bdff442cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "663ee546-da26-45fd-a766-8bdcb40694ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "svm = LinearSVC(labelCol='label',\n",
    "                        featuresCol='scaledFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, svm])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.maxIter, [10, 20, 30, 40, 50]) \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01, .001]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "svmModel = crossval.setParallelism(6).fit(train) # train 6 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35c69c9-c60e-4793-8ad8-a1f21d27dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_090fc820782b__maxIter: 10\n",
      "LinearSVC_090fc820782b__regParam: 0.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = svmModel.getEstimatorParamMaps()[np.argmax(svmModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "940dcbbd-0929-4a74-97ce-96c1bdd79d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_prediction = svmModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae55b58b-bd06-4d05-8c3b-3630e4c7e50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7547770700636943\n",
      "Precision: 0.7897435897435897\n",
      "Recall: 0.8105263157894737\n",
      "F1 Score: 0.7538465571020418\n",
      "AUROC: 0.7399405772495755\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(svm_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236efbb-0621-4252-b841-d4e3449f7a06",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9360558-e736-447c-962d-c67b2777b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d797fe7-d9d8-47a4-9391-b3aef46da0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "gbt = GBTClassifier(labelCol='label',\n",
    "                        featuresCol='features')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, gbt])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10, 20, 30]) \\\n",
    "    .addGrid(gbt.maxBins, [8, 16, 32,64]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "gbtModel = crossval.setParallelism(6).fit(train) # train 6 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6720cf52-ba0e-41f0-998a-f97de87baf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier_686a01b5d611__maxDepth: 10\n",
      "GBTClassifier_686a01b5d611__maxBins: 64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = gbtModel.getEstimatorParamMaps()[np.argmax(gbtModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1dcb4517-0c1d-45be-9fdf-57b68ee69c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_prediction = gbtModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd60359a-c422-42b2-830a-c1c90e9242c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7133757961783439\n",
      "Precision: 0.7551020408163265\n",
      "Recall: 0.7789473684210526\n",
      "F1 Score: 0.7120502528214845\n",
      "AUROC: 0.6959252971137521\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(gbt_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
