{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c1af0c-0125-4bea-abab-5654483a5666",
   "metadata": {},
   "source": [
    "# Build Depression Models \n",
    "This notebook contains all the code necessary to build, cross validate, and evaluate our models for Depression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa166c-6641-41c2-a4d1-103bb39aa47f",
   "metadata": {},
   "source": [
    "# Load in Data and Explore Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fae1bf-8475-4249-8be9-0288d4d914ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "DATA_FILEPATH = 'data/depression.csv'\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Preprocessing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(DATA_FILEPATH,  inferSchema=True, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2715ac7a-1f37-4191-ac44-03c141a73bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SES: double (nullable = true)\n",
      " |-- RuralVsUrban: double (nullable = true)\n",
      " |-- EducationDegree: double (nullable = true)\n",
      " |-- SecondaryVsPrimary: double (nullable = true)\n",
      " |-- TeachPublicVsOther: double (nullable = true)\n",
      " |-- YearsAsTeacher: double (nullable = true)\n",
      " |-- EmployedVsNot: double (nullable = true)\n",
      " |-- PastCOVIDpositive: double (nullable = true)\n",
      " |-- COVIDvaccinated: double (nullable = true)\n",
      " |-- PrePandemicChronIllness: double (nullable = true)\n",
      " |-- PrePandemicMentIllness: double (nullable = true)\n",
      " |-- PrePandemicNeuroDis: double (nullable = true)\n",
      " |-- Depression: integer (nullable = true)\n",
      " |-- Anxiety: integer (nullable = true)\n",
      " |-- OverallHealth: double (nullable = true)\n",
      " |-- COVIDfear: double (nullable = true)\n",
      " |-- RelatImprov: double (nullable = true)\n",
      " |-- WorkloadNowVsPreCOVID: double (nullable = true)\n",
      " |-- ResourceSatisfaction: double (nullable = true)\n",
      " |-- SufficientCOVIDmeasures: double (nullable = true)\n",
      " |-- MonthsOnlineTeach: double (nullable = true)\n",
      " |-- EducProblems: double (nullable = true)\n",
      " |-- BehavProblems: double (nullable = true)\n",
      " |-- EmotProblems: double (nullable = true)\n",
      " |-- SocialProblems: double (nullable = true)\n",
      " |-- FamilyProblems: double (nullable = true)\n",
      " |-- DiffOnlineTeach: double (nullable = true)\n",
      " |-- InstructAdjust: double (nullable = true)\n",
      " |-- BenefitOnlineTeach: double (nullable = true)\n",
      " |-- TotOnlineTraining: double (nullable = true)\n",
      " |-- BurnoutEmotExhaust: double (nullable = true)\n",
      " |-- BurnoutDepersonal: double (nullable = true)\n",
      " |-- BurnoutPerFulfill: double (nullable = true)\n",
      " |-- Man: integer (nullable = true)\n",
      " |-- Partnered: integer (nullable = true)\n",
      " |-- Bachelor's Degree: integer (nullable = true)\n",
      " |-- Diploma: integer (nullable = true)\n",
      " |-- Master's Degree: integer (nullable = true)\n",
      " |-- Non_university_studies: integer (nullable = true)\n",
      " |-- PhD: integer (nullable = true)\n",
      " |-- Postdoctoral Fellowship: integer (nullable = true)\n",
      " |-- 0-5 years: integer (nullable = true)\n",
      " |-- 6-11 years: integer (nullable = true)\n",
      " |-- 12-16 years: integer (nullable = true)\n",
      " |-- 17-18 years: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00366d9-340c-4442-81b7-38b66ec3284d",
   "metadata": {},
   "source": [
    "# Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a30a2d-7105-4604-a761-8eaa99a7956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.85, 0.15], 314)\n",
    "column_list = train.columns\n",
    "column_list.remove('Depression')\n",
    "column_list.remove('_c0')\n",
    "train = train.withColumnRenamed('Depression', 'label')\n",
    "test = test.withColumnRenamed('Depression', 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607b35b-8b55-49b7-b191-189093d6d18b",
   "metadata": {},
   "source": [
    "# Benchmark Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d131513-d3b8-4bd7-941e-507057ffb1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8819e96-0845-4f30-a1ff-20fe9d816286",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "lr = LogisticRegression(labelCol='label',\n",
    "                        featuresCol='scaledFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, lr])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.elasticNetParam, [0, .2, .4, .5, .6, .8, 1]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01, .001]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "cvModel = crossval.setParallelism(4).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3f172b0-745b-401c-a9a0-4304745486b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression_13cbfb8096b0__elasticNetParam: 0.6\n",
      "LogisticRegression_13cbfb8096b0__regParam: 0.01\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = cvModel.getEstimatorParamMaps()[np.argmax(cvModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1887be5c-eb4c-4b5b-aff7-d253dadfbbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37f17e13-aa9a-4f02-80e9-561cb4794d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7509727626459144\n",
      "Precision: 0.7686274509803922\n",
      "Recall: 0.7396226415094339\n",
      "F1 Score: 0.7510293254648168\n",
      "AUROC: 0.7513374251723878\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(prediction)\n",
    "#confusion_matrix = evaluator.evaluate(prediction, {evaluator.metricName: \"confusionMatrix\"})\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")\n",
    "#print(f\"Confusion Matrix:\\n{confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77ada38-e17c-4ae7-8742-3ddd559d1597",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8d3595f-65f4-449a-b38d-088fbed88b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c95ea0-3cd8-4170-a7a3-5d51aebd66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "rf = RandomForestClassifier(labelCol='label',\n",
    "                        featuresCol='scaledFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, rf])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [1, 5, 10, 15]) \\\n",
    "    .addGrid(rf.numTrees, [10, 15, 20, 25, 30, 35, 40, 45]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "rfModel = crossval.setParallelism(4).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17a314dd-aa9f-441c-8f39-d48d5752db36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier_97119562daf6__maxDepth: 15\n",
      "RandomForestClassifier_97119562daf6__numTrees: 45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = rfModel.getEstimatorParamMaps()[np.argmax(rfModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7434544d-25fb-409e-9023-8a57d4db8c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param set 1 Avg Metrics: 0.8288257081099475\n",
      "  maxDepth: 1\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 2 Avg Metrics: 0.823365195230668\n",
      "  maxDepth: 1\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 3 Avg Metrics: 0.843800324808525\n",
      "  maxDepth: 1\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 4 Avg Metrics: 0.8353203075512105\n",
      "  maxDepth: 1\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 5 Avg Metrics: 0.834049730165862\n",
      "  maxDepth: 1\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 6 Avg Metrics: 0.8306092667991258\n",
      "  maxDepth: 1\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 7 Avg Metrics: 0.8220845752044051\n",
      "  maxDepth: 1\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 8 Avg Metrics: 0.820395651292074\n",
      "  maxDepth: 1\n",
      "  numTrees: 45\n",
      "\n",
      "Param set 9 Avg Metrics: 0.8915832855369671\n",
      "  maxDepth: 5\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 10 Avg Metrics: 0.8932436476529284\n",
      "  maxDepth: 5\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 11 Avg Metrics: 0.898807289136832\n",
      "  maxDepth: 5\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 12 Avg Metrics: 0.8980281131870574\n",
      "  maxDepth: 5\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 13 Avg Metrics: 0.9023377364574684\n",
      "  maxDepth: 5\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 14 Avg Metrics: 0.9004643927327829\n",
      "  maxDepth: 5\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 15 Avg Metrics: 0.8989720710604052\n",
      "  maxDepth: 5\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 16 Avg Metrics: 0.9019113344458203\n",
      "  maxDepth: 5\n",
      "  numTrees: 45\n",
      "\n",
      "Param set 17 Avg Metrics: 0.9779635583851087\n",
      "  maxDepth: 10\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 18 Avg Metrics: 0.9848940599584484\n",
      "  maxDepth: 10\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 19 Avg Metrics: 0.9838894246542795\n",
      "  maxDepth: 10\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 20 Avg Metrics: 0.9861485380702668\n",
      "  maxDepth: 10\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 21 Avg Metrics: 0.9853451181343496\n",
      "  maxDepth: 10\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 22 Avg Metrics: 0.9861834655802039\n",
      "  maxDepth: 10\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 23 Avg Metrics: 0.9856984135905416\n",
      "  maxDepth: 10\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 24 Avg Metrics: 0.9872981578721265\n",
      "  maxDepth: 10\n",
      "  numTrees: 45\n",
      "\n",
      "Param set 25 Avg Metrics: 0.9902377752158611\n",
      "  maxDepth: 15\n",
      "  numTrees: 10\n",
      "\n",
      "Param set 26 Avg Metrics: 0.9940278645007082\n",
      "  maxDepth: 15\n",
      "  numTrees: 15\n",
      "\n",
      "Param set 27 Avg Metrics: 0.9925170921826753\n",
      "  maxDepth: 15\n",
      "  numTrees: 20\n",
      "\n",
      "Param set 28 Avg Metrics: 0.9933912784594017\n",
      "  maxDepth: 15\n",
      "  numTrees: 25\n",
      "\n",
      "Param set 29 Avg Metrics: 0.9937510111401235\n",
      "  maxDepth: 15\n",
      "  numTrees: 30\n",
      "\n",
      "Param set 30 Avg Metrics: 0.9942807577115501\n",
      "  maxDepth: 15\n",
      "  numTrees: 35\n",
      "\n",
      "Param set 31 Avg Metrics: 0.9948234215170343\n",
      "  maxDepth: 15\n",
      "  numTrees: 40\n",
      "\n",
      "Param set 32 Avg Metrics: 0.9951001600789926\n",
      "  maxDepth: 15\n",
      "  numTrees: 45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = rfModel.avgMetrics\n",
    "all_params = rfModel.getEstimatorParamMaps()\n",
    "params= []\n",
    "for i in range(0, len(all_params)):\n",
    "    param = all_params[i]\n",
    "    for k, v in param.items():\n",
    "        params.append({f\"{k}\": f\"{v}\"})     \n",
    "for i in range(0, len(metrics)):\n",
    "    s = f'Param set {i+1} Avg Metrics: {metrics[i]}\\n'\n",
    "    params = all_params[i]\n",
    "    for k, v in params.items():\n",
    "#         kname = str(k).split('__')[-1]\n",
    "        s+= f\"  {k.name}: {v}\\n\"\n",
    "#         print(k.name)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c392b3f4-e618-471b-b882-a7c77db3fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_prediction = rfModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f2414d8-43a7-4d55-bade-da3c98c169b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9494163424124513\n",
      "Precision: 0.995850622406639\n",
      "Recall: 0.9056603773584906\n",
      "F1 Score: 0.9493795726827072\n",
      "AUROC: 0.9508221565507312\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(rf_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(rf_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")\n",
    "#print(f\"Confusion Matrix:\\n{confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a5ba5-5721-49ed-9fb7-76c65a642d09",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2eaecdc-e596-46e4-97b7-4d21ca9b0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7833a575-d2d6-4f14-9714-af0119415c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [[len(column_list), k, k, 2] for k in [50, 75, 100]]\n",
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(labelCol='label', featuresCol='scaledFeatures', maxIter=1000, \n",
    "                                     blockSize=128, seed=1234, solver = 'gd')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, mlp])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(mlp.layers, layers)\\\n",
    "    .addGrid(mlp.stepSize, [.001, .005, .01, .05])\\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "# train the model\n",
    "mlpModel = crossval.setParallelism(6).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3528dd53-0d36-4e0c-a61f-9e94f2e418fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilayerPerceptronClassifier_87f75b233eb4__layers: [45, 100, 100, 2]\n",
      "MultilayerPerceptronClassifier_87f75b233eb4__stepSize: 0.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = mlpModel.getEstimatorParamMaps()[np.argmax(mlpModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "674f710b-7d76-4576-ad46-36359697209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_prediction = mlpModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2574e262-2973-4dda-9e7e-35730c30e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7490272373540856\n",
      "Precision: 0.788135593220339\n",
      "Recall: 0.7018867924528301\n",
      "F1 Score: 0.7486688772942527\n",
      "AUROC: 0.7505417898007123\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(mlp_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(mlp_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")\n",
    "#print(f\"Confusion Matrix:\\n{confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bcb33-9f26-4afa-9c65-1f79870bd1bb",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef3e0ff0-6c5a-4cec-86d4-4bdff442cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "663ee546-da26-45fd-a766-8bdcb40694ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "svm = LinearSVC(labelCol='label',\n",
    "                        featuresCol='scaledFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, svm])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.maxIter, [10, 20, 30, 40, 50]) \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01, .001]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "svmModel = crossval.setParallelism(6).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f35c69c9-c60e-4793-8ad8-a1f21d27dd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_a5385fc9032e__maxIter: 10\n",
      "LinearSVC_a5385fc9032e__regParam: 0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = svmModel.getEstimatorParamMaps()[np.argmax(svmModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "940dcbbd-0929-4a74-97ce-96c1bdd79d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_prediction = svmModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae55b58b-bd06-4d05-8c3b-3630e4c7e50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7412451361867705\n",
      "Precision: 0.7844827586206896\n",
      "Recall: 0.6867924528301886\n",
      "F1 Score: 0.7406950883343102\n",
      "AUROC: 0.7429946199893915\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(svm_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(svm_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")\n",
    "#print(f\"Confusion Matrix:\\n{confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e236efbb-0621-4252-b841-d4e3449f7a06",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9360558-e736-447c-962d-c67b2777b00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d797fe7-d9d8-47a4-9391-b3aef46da0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=column_list,\n",
    "                            outputCol=\"features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\")\n",
    "\n",
    "gbt = GBTClassifier(labelCol='label',\n",
    "                        featuresCol='scaledFeatures')\n",
    "\n",
    "pipeline = Pipeline(stages = [assembler, scaler, gbt])\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxDepth, [5, 10, 20, 30]) \\\n",
    "    .addGrid(gbt.maxBins, [8, 16, 32,64]) \\\n",
    "    .build()\n",
    "\n",
    "# Fit the model\n",
    "crossval = CrossValidator(estimator=pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(),\n",
    "                          numFolds=4)\n",
    "\n",
    "gbtModel = crossval.setParallelism(6).fit(train) # train 4 models in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6720cf52-ba0e-41f0-998a-f97de87baf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBTClassifier_a24fadf68a87__maxDepth: 10\n",
      "GBTClassifier_a24fadf68a87__maxBins: 16\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "best_params = gbtModel.getEstimatorParamMaps()[np.argmax(gbtModel.avgMetrics)]\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dcb4517-0c1d-45be-9fdf-57b68ee69c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_prediction = gbtModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd60359a-c422-42b2-830a-c1c90e9242c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.914396887159533\n",
      "Precision: 1.0\n",
      "Recall: 0.8339622641509434\n",
      "F1 Score: 0.9139965142265631\n",
      "AUROC: 0.9169811320754717\n"
     ]
    }
   ],
   "source": [
    "# set up evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\")\n",
    "evaluator_2 = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\",\n",
    "                                          labelCol=\"label\",\n",
    "                                          metricName=\"areaUnderROC\")\n",
    "#Evaluate Metrics\n",
    "accuracy = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"precisionByLabel\"})\n",
    "recall = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"recallByLabel\"})\n",
    "f1_score = evaluator.evaluate(gbt_prediction, {evaluator.metricName: \"f1\"})\n",
    "auc = evaluator_2.evaluate(gbt_prediction)\n",
    "\n",
    "#Print Results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(f\"AUROC: {auc}\")\n",
    "#print(f\"Confusion Matrix:\\n{confusion_matrix}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
